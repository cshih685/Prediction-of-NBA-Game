{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- programming start---\n",
      "Collecting tweets...\n",
      "Get result from /Users/cosoet/SIT/BIA660-WebAnalytics/FinalProject/PythonCode/GameResult/Thunder.csv\n",
      "--- programming end---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import re\n",
    "import sample_package.commonFunction as basefunc\n",
    "import sample_package.filterMethod as filter_TFID\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from numpy  import array\n",
    "import numpy as np\n",
    "from scipy.misc import toimage\n",
    "\n",
    "\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "foundCnt = 0;\n",
    "foundMax = 1000;\n",
    "tweetIn=[];\n",
    "labelIn=[];\n",
    "nrow='';\n",
    "text = []\n",
    "target = []\n",
    "\n",
    "# get Game Infomation\n",
    "\n",
    "    \n",
    "print(\"--- programming start---\")\n",
    "print(\"Collecting tweets...\")\n",
    "\n",
    "#let's try team \"Thunder\" far example\n",
    "# if you want to try multiple teams, append team names into list.\n",
    "teamNameList = [\"Thunder\"] # , \"Blazers\",\"Grizzlies\"\n",
    "\n",
    "for teamName in teamNameList:\n",
    "\n",
    "    gameInfo = basefunc.getGameInfo(teamName);\n",
    "\n",
    "    for eachGameInfo in gameInfo:\n",
    "\n",
    "        # Game data and time\n",
    "        gameDate = eachGameInfo.Date\n",
    "        gameTime = eachGameInfo.Time\n",
    "\n",
    "\n",
    "#         print(\"Team: {} Date: {} {}\".format(teamName, gameDate, eachGameInfo.result))\n",
    "        fileName = basefunc.getCvsPathByGameData(teamName, gameDate)\n",
    "        foundCnt+=1\n",
    "        if (len(fileName) == 0):\n",
    "            continue;\n",
    "        \n",
    "        fileName = ''.join(fileName)\n",
    "        nrow='';\n",
    "        file=open(fileName, 'r', encoding='utf-8')\n",
    "        csvCursor=csv.reader(file)\n",
    "        \n",
    "        for idx, row in enumerate(csvCursor):\n",
    "            if idx>0:\n",
    "        #For here,if you want to run with sentiment, please comment block 1. and open block 2.\n",
    "\n",
    "                #-------------block 1. without sentiment-------------#\n",
    "                # remove http link\n",
    "                tpt = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', row[0], flags=re.MULTILINE)\n",
    "                # remove team's name\n",
    "                tpt = tpt.replace(teamName, '')\n",
    "                nrow+=tpt\n",
    "                #------------- end of block 1. -----------#\n",
    "\n",
    "\n",
    "                #-------------block 2. sentiment-------------\n",
    "                # remove \n",
    "#                 tpt = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', row[0], flags=re.MULTILINE)\n",
    "#                 tpresult = sid.polarity_scores(tpt)\n",
    "#                 if(tpresult[\"compound\"] != 0):\n",
    "#                     tpt = tpt.replace(teamName, '')\n",
    "#                     nrow += tpt\n",
    "            #------------- end of block 2. ------------#\n",
    "        tweetIn.append(nrow)\n",
    "        \n",
    "        if(eachGameInfo.result=='W'):        \n",
    "            labelIn.append(eachGameInfo.result)\n",
    "        elif(eachGameInfo.result=='L'):\n",
    "            labelIn.append(eachGameInfo.result)\n",
    "\n",
    "        \n",
    "\n",
    "    if foundCnt >= foundMax:\n",
    "        break;\n",
    "print(\"--- programming end---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4e20b5e3454c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#running Naive Bayes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m pipeline = Pipeline([\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'vect'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'english'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "#for here, we are running Naive Bayes now.\n",
    "#If you want to run Naive Bayes, please open block NV and comment block SVM.\n",
    "\n",
    "#---------- NV --------------#  \n",
    "\n",
    "#running Naive Bayes\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words = 'english', min_df=0.05, max_df=0.75)),\n",
    "    ('clf', MultinomialNB()),    \n",
    "])\n",
    "\n",
    "labels=sorted(list(set(labelIn)))\n",
    "\n",
    "\n",
    "pipeline.fit(x_train, y_train)\n",
    "y_predicted = pipeline.predict(x_test)\n",
    "print(\"Running Naive Bayes: \\n\")\n",
    "print(metrics.classification_report(y_test, y_predicted, target_names = labels))\n",
    "\n",
    "#----------end of NV --------------#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SVM: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          L       0.00      0.00      0.00         1\n",
      "          W       0.80      0.57      0.67         7\n",
      "\n",
      "avg / total       0.70      0.50      0.58         8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#---------- SVM --------------#\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words = 'english', min_df=0.05, max_df=0.75)),  \n",
    "    ('clf', OneVsRestClassifier(LinearSVC())),\n",
    "])\n",
    "\n",
    "\n",
    "labels=sorted(list(set(labelIn)))\n",
    "\n",
    "\n",
    "pipeline.fit(x_train, y_train)\n",
    "y_predicted = pipeline.predict(x_test)\n",
    "print(\"Running SVM: \\n\")\n",
    "print(metrics.classification_report(y_test, y_predicted, target_names = labels))\n",
    "\n",
    "#----------end of SVM --------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
