{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- programming start---\n",
      "Collecting tweets...\n",
      "Get result from /Users/cosoet/SIT/BIA660-WebAnalytics/FinalProject/PythonCode/GameResult/Thunder.csv\n",
      "--- programming end---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import re\n",
    "import sample_package.commonFunction as basefunc\n",
    "import sample_package.filterMethod as filter_TFID\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from numpy  import array\n",
    "import numpy as np\n",
    "from scipy.misc import toimage\n",
    "\n",
    "\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "foundCnt = 0;\n",
    "foundMax = 1000;\n",
    "tweetIn=[];\n",
    "labelIn=[];\n",
    "nrow='';\n",
    "text = []\n",
    "target = []\n",
    "\n",
    "# get Game Infomation\n",
    "\n",
    "    \n",
    "print(\"--- programming start---\")\n",
    "print(\"Collecting tweets...\")\n",
    "\n",
    "#let's try team \"Thunder\" far example\n",
    "# if you want to try multiple teams, append team names into list.\n",
    "teamNameList = [\"Thunder\"] # , \"Blazers\",\"Grizzlies\"\n",
    "\n",
    "for teamName in teamNameList:\n",
    "\n",
    "    gameInfo = basefunc.getGameInfo(teamName);\n",
    "\n",
    "    for eachGameInfo in gameInfo:\n",
    "\n",
    "        # Game data and time\n",
    "        gameDate = eachGameInfo.Date\n",
    "        gameTime = eachGameInfo.Time\n",
    "\n",
    "\n",
    "#         print(\"Team: {} Date: {} {}\".format(teamName, gameDate, eachGameInfo.result))\n",
    "        fileName = basefunc.getCvsPathByGameData(teamName, gameDate)\n",
    "        foundCnt+=1\n",
    "        if (len(fileName) == 0):\n",
    "            continue;\n",
    "        \n",
    "        fileName = ''.join(fileName)\n",
    "        nrow='';\n",
    "        file=open(fileName, 'r', encoding='utf-8')\n",
    "        csvCursor=csv.reader(file)\n",
    "        \n",
    "        for idx, row in enumerate(csvCursor):\n",
    "            if idx>0:\n",
    "        #For here,if you want to run with sentiment, please comment block 1. and open block 2.\n",
    "\n",
    "                #-------------block 1. without sentiment-------------#\n",
    "                # remove http link\n",
    "                tpt = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', row[0], flags=re.MULTILINE)\n",
    "                # remove team's name\n",
    "                tpt = tpt.replace(teamName, '')\n",
    "                nrow+=tpt\n",
    "                #------------- end of block 1. -----------#\n",
    "\n",
    "\n",
    "                #-------------block 2. sentiment-------------\n",
    "                # remove \n",
    "#                 tpt = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', row[0], flags=re.MULTILINE)\n",
    "#                 tpresult = sid.polarity_scores(tpt)\n",
    "#                 if(tpresult[\"compound\"] != 0):\n",
    "#                     tpt = tpt.replace(teamName, '')\n",
    "#                     nrow += tpt\n",
    "            #------------- end of block 2. ------------#\n",
    "        tweetIn.append(nrow)\n",
    "        \n",
    "        if(eachGameInfo.result=='W'):        \n",
    "            labelIn.append(eachGameInfo.result)\n",
    "        elif(eachGameInfo.result=='L'):\n",
    "            labelIn.append(eachGameInfo.result)\n",
    "\n",
    "        \n",
    "\n",
    "    if foundCnt >= foundMax:\n",
    "        break;\n",
    "print(\"--- programming end---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cosoet/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\\\n",
    "    tweetIn, labelIn, test_size=0.1, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Naive Bayes: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          L       0.00      0.00      0.00         4\n",
      "          W       0.50      0.80      0.62         5\n",
      "\n",
      "avg / total       0.28      0.44      0.34         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#for here, we are running Naive Bayes now.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "#If you want to run Naive Bayes, please open block NV and comment block SVM.\n",
    "\n",
    "#---------- NV --------------#  \n",
    "\n",
    "#running Naive Bayes\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words = 'english', min_df=0.05, max_df=0.75)),\n",
    "    ('clf', MultinomialNB()),    \n",
    "])\n",
    "\n",
    "labels=sorted(list(set(labelIn)))\n",
    "\n",
    "\n",
    "pipeline.fit(x_train, y_train)\n",
    "y_predicted = pipeline.predict(x_test)\n",
    "print(\"Running Naive Bayes: \\n\")\n",
    "print(metrics.classification_report(y_test, y_predicted, target_names = labels))\n",
    "\n",
    "#----------end of NV --------------#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SVM: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          L       0.00      0.00      0.00         4\n",
      "          W       0.50      0.80      0.62         5\n",
      "\n",
      "avg / total       0.28      0.44      0.34         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#---------- SVM --------------#\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer(stop_words = 'english', min_df=0.05, max_df=0.75)),  \n",
    "    ('clf', OneVsRestClassifier(LinearSVC())),\n",
    "])\n",
    "\n",
    "\n",
    "labels=sorted(list(set(labelIn)))\n",
    "\n",
    "\n",
    "pipeline.fit(x_train, y_train)\n",
    "y_predicted = pipeline.predict(x_test)\n",
    "print(\"Running SVM: \\n\")\n",
    "print(metrics.classification_report(y_test, y_predicted, target_names = labels))\n",
    "\n",
    "#----------end of SVM --------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
